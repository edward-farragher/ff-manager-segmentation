{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to level up to import functions\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_most_recent_file():\n",
    "    # Define the pattern to match timestamped CSV files in the current directory\n",
    "    pattern = 'data/*_team_sample_data.csv'\n",
    "    \n",
    "    # List all files matching the pattern\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No files found matching the pattern.\")\n",
    "    \n",
    "    # Sort files alphabetically (most recent file will be the last in the sorted list)\n",
    "    files.sort()\n",
    "    \n",
    "    # Get the most recent file\n",
    "    most_recent_file = files[-1]\n",
    "    \n",
    "    # Load the most recent file into a DataFrame\n",
    "    df = pd.read_csv(most_recent_file)\n",
    "    \n",
    "    # Remove the prefix 'data/' or 'data\\' and the suffix '_team_sample_data.csv' from the file name\n",
    "    base_name = most_recent_file.replace('data/', '').replace('data\\\\', '').replace('_team_sample_data.csv', '')\n",
    "    \n",
    "    return df, base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_proportion_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame with the proportion of each value in the specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column_name: str, the name of the column to calculate proportions for\n",
    "    \n",
    "    Returns:\n",
    "    - pandas DataFrame with an additional column for the proportion of each value\n",
    "    \"\"\"\n",
    "    # Calculate the proportion of each unique value\n",
    "    value_counts = df[column_name].value_counts(normalize=True)\n",
    "    \n",
    "    # Create the new column name\n",
    "    prop_column_name = f\"{column_name}_prop\"\n",
    "    \n",
    "    # Map these proportions to a new column in the DataFrame\n",
    "    df[prop_column_name] = df[column_name].map(value_counts)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_percentiles(df, columns_to_percentile):\n",
    "    \n",
    "    for column, order in columns_to_percentile.items():\n",
    "        if order == 'asc':\n",
    "            # Create percentile bins using qcut\n",
    "            df[f'{column}_percentile'] = pd.qcut(df[column], q=100, labels=False, duplicates='drop') + 1\n",
    "        elif order == 'desc':\n",
    "            # Create percentile bins in descending order\n",
    "            df[f'{column}_percentile'] = pd.qcut(-df[column], q=100, labels=False, duplicates='drop') + 1\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid order '{order}' specified for column '{column}'. Must be 'asc' or 'desc'.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_percentiles_partitioned(df, columns_to_percentile_partitioned):\n",
    "    \n",
    "    for details in columns_to_percentile_partitioned:\n",
    "        column_name = details['column_name']\n",
    "        partition_column = details['partition_column']\n",
    "        order = details.get('order', 'asc')\n",
    "\n",
    "        # Validate inputs\n",
    "        if not column_name or not partition_column:\n",
    "            raise ValueError(\"Both 'column_name' and 'partition_column' must be provided.\")\n",
    "        if order not in ['asc', 'desc']:\n",
    "            raise ValueError(\"Order must be 'asc' or 'desc'\")\n",
    "\n",
    "        # Apply the computation excluding grouping columns\n",
    "        if order == 'asc':\n",
    "            df[f'{column_name}_partitioned_percentile'] = (\n",
    "                df.groupby(partition_column, group_keys=False)[column_name]\n",
    "                  .apply(lambda x: pd.qcut(x, q=100, labels=False, duplicates='drop') + 1)\n",
    "                  .reset_index(level=0, drop=True)\n",
    "            )\n",
    "        elif order == 'desc':\n",
    "            df[f'{column_name}_partitioned_percentile'] = (\n",
    "                df.groupby(partition_column, group_keys=False)[column_name]\n",
    "                  .apply(lambda x: pd.qcut(-x, q=100, labels=False, duplicates='drop') + 1)\n",
    "                  .reset_index(level=0, drop=True)\n",
    "            )\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentile_look_up_csv(df,column_name_value):\n",
    "    column_name_percentile = f'{column_name_value}_percentile'\n",
    "    percentile_look_up = df[[column_name_value, column_name_percentile]].drop_duplicates()\n",
    "\n",
    "    percentile_look_up.to_csv(f'data/profile_look_up/{snapshot_dt}_{column_name_value}.csv', index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "def create_proportion_look_up_csv(df,column_name_value, order):\n",
    "    column_name_prop = f'{column_name_value}_prop'\n",
    "    if order == 'asc':\n",
    "        order = True\n",
    "    else:\n",
    "        order = False\n",
    "    proportion_look_up = df[[column_name_value, column_name_prop]].drop_duplicates()\n",
    "\n",
    "    proportion_look_up.to_csv(f'data/profile_look_up/{snapshot_dt}_{column_name_value}.csv', index=False)\n",
    "    proportion_look_up['rank_descending'] = proportion_look_up['player_region_iso_code_long_prop'].rank(method='min', ascending={order})\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,snapshot_dt = load_most_recent_file()\n",
    "\n",
    "# Dictionary with fill values for each column\n",
    "fill_values = {\n",
    "    'career_break_history': 0,   \n",
    "    'kit': 'No Kit',\n",
    "    'kit': 'No Kit',\n",
    "    'kit_shirt_type': 'No Kit Shirt',\n",
    "    'kit_shirt_logo': 'No Kit Logo',\n",
    "    'kit_socks_type': 'No Kit Socks',\n",
    "}\n",
    "\n",
    "# Fill NaN values in each column with specified values\n",
    "df = df.fillna(value=fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cateogorical to proportion share\n",
    "columns_to_prop = [\n",
    "    'player_region_iso_code_long',\n",
    "    'name_change_blocked',\n",
    "    'kit',\n",
    "    'kit_shirt_type',\n",
    "    'kit_shirt_logo',\n",
    "    'kit_socks_type'\n",
    "    ]\n",
    "\n",
    "for column_name in columns_to_prop:\n",
    "    df=add_proportion_column(df=df, column_name=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentile\n",
    "columns_to_percentile = {\n",
    "    'classic_leagues_competed_in' : 'desc',\n",
    "    'h2h_leagues_competed_in' : 'desc',\n",
    "    'last_deadline_bank' : 'desc',\n",
    "    'last_deadline_value' : 'desc',\n",
    "    'last_deadline_total_transfers' : 'desc',\n",
    "    'summary_overall_points' : 'desc',\n",
    "    'summary_overall_rank' : 'desc',\n",
    "    'leagues_admin' : 'desc',\n",
    "    'min_rank_history' : 'asc',\n",
    "    'max_total_points_history' : 'desc',\n",
    "    'earliest_season_year_history' : 'asc',\n",
    "    'career_break_history' : 'desc',\n",
    "    'seasons_played_in' : 'desc',\n",
    "}\n",
    "\n",
    "# Apply percentiles based on the specified order\n",
    "df = calculate_percentiles(df=df, columns_to_percentile=columns_to_percentile)\n",
    "\n",
    "columns_to_percentile_partitioned = [\n",
    "    {'column_name' : 'stdev_rank_history',\n",
    "     'partition_column' : 'seasons_played_in',\n",
    "     'order' : 'desc'\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "df=calculate_percentiles_partitioned(df=df, columns_to_percentile_partitioned=columns_to_percentile_partitioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_percentile = {\n",
    "    'classic_leagues_competed_in' : 'desc',\n",
    "    'h2h_leagues_competed_in' : 'desc',\n",
    "    'last_deadline_bank' : 'desc',\n",
    "    'last_deadline_value' : 'desc',\n",
    "    'last_deadline_total_transfers' : 'desc',\n",
    "    'summary_overall_points' : 'desc',\n",
    "    'summary_overall_rank' : 'desc',\n",
    "    'leagues_admin' : 'desc',\n",
    "    'min_rank_history' : 'asc',\n",
    "    'max_total_points_history' : 'desc',\n",
    "    'earliest_season_year_history' : 'asc',\n",
    "    'career_break_history' : 'desc',\n",
    "    'seasons_played_in' : 'desc',\n",
    "}\n",
    "\n",
    "# Apply percentiles based on the specified order\n",
    "df = calculate_percentiles(df=df, columns_to_percentile=columns_to_percentile)\n",
    "\n",
    "columns_to_percentile_partitioned = [\n",
    "    {'column_name' : 'stdev_rank_history',\n",
    "     'partition_column' : 'seasons_played_in',\n",
    "     'order' : 'desc'\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_cols = ['classic_leagues_competed_in', 'h2h_leagues_competed_in', 'last_deadline_bank', 'last_deadline_value', 'last_deadline_total_transfers', 'summary_overall_points', 'summary_overall_rank', 'leagues_admin', 'min_rank_history', 'max_total_points_history', 'earliest_season_year_history', 'career_break_history', 'seasons_played_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in percentile_cols:\n",
    "    create_percentile_look_up_csv(df=df,column_name_value=column)\n",
    "\n",
    "# NEED TO DO _partitioned_percentile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
